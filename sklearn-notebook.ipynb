{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with SciKit Learn\n",
    "\n",
    "## Resources\n",
    "- http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "- https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n",
    "\n",
    "## MDSD File Sizes\n",
    "```\n",
    "1.4G sorted_data/books/all.review\n",
    "217M sorted_data/music/all.review\n",
    "198M sorted_data/dvd/all.review\n",
    " 56M sorted_data/video/all.review\n",
    " 24M sorted_data/electronics/all.review\n",
    " 19M sorted_data/kitchen_&_housewares/all.review\n",
    " 13M sorted_data/toys_&_games/all.review\n",
    "8.7M sorted_data/camera_&_photo/all.review\n",
    "7.0M sorted_data/apparel/all.review\n",
    "6.8M sorted_data/health_&_personal_care/all.review\n",
    "5.7M sorted_data/sports_&_outdoors/all.review\n",
    "4.9M sorted_data/magazines/all.review\n",
    "4.4M sorted_data/computer_&_video_games/all.review\n",
    "4.2M sorted_data/baby/all.review\n",
    "2.9M sorted_data/software/all.review\n",
    "2.7M sorted_data/beauty/all.review\n",
    "2.3M sorted_data/grocery/all.review\n",
    "1.7M sorted_data/jewelry_&_watches/all.review\n",
    "1.5M sorted_data/outdoor_living/all.review\n",
    "1.5M sorted_data/gourmet_food/all.review\n",
    "1.1M sorted_data/cell_phones_&_service/all.review\n",
    "654K sorted_data/automotive/all.review\n",
    "444K sorted_data/office_products/all.review\n",
    "315K sorted_data/musical_instruments/all.review\n",
    "110K sorted_data/tools_&_hardware/all.review\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\Owner\\Projects\\ml-review-classification\\sorted_data\\electronics\\all.review\n",
      "Lines: 868686\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 868686/868686 [00:08<00:00, 98138.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews: 23009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mdsd \n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "file = Path(\"../sorted_data/software/all.review\")    # 2390 Reviews\n",
    "file = Path(\"../sorted_data/electronics/all.review\") # 23009 Reviews\n",
    "\n",
    "# sklearn uses slightly different structures\n",
    "data        = mdsd.parse_file(file)\n",
    "targets     = numpy.array(list(map(lambda x: x['rating'], data)))\n",
    "review_text = list(map(lambda x: x['text'], data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Stars:  ☆☆☆☆☆\n",
      "Review Text:  When checking printers in\" Consumer Reports \" this was rated \"best buy\".I see no reason to call it anything else\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seperate into train and test datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "review_train, review_test, target_train, target_test = train_test_split(review_text, targets, test_size=0.10)\n",
    "\n",
    "print('Review Stars: ' , '☆' * int(target_train[0]))\n",
    "print('Review Text: ' , review_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20708, 33831)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Extraction - Get count of words \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect     = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(review_train)\n",
    "\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From occurrences to frequencies\n",
    "\n",
    "Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.\n",
    "\n",
    "To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called tf for Term Frequencies.\n",
    "\n",
    "Another refinement on top of tf is to downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.\n",
    "\n",
    "This downscaling is called tf–idf for “Term Frequency times Inverse Document Frequency”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20708, 33831)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf     = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.672%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_test_counts = count_vect.transform(review_test)\n",
    "x_test_tfidf  = tfidf_transformer.transform(x_test_counts)\n",
    "score         = round(clf.score(x_test_tfidf, target_test) * 100, 3)\n",
    "\n",
    "print('Accuracy: {}%'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Linear Support Vector Machine (SVM)](http://scikit-learn.org/stable/modules/svm.html#svm)\n",
    "\n",
    "Widely regarded as one of the best text classification algorithms (although it’s also a bit slower than naïve Bayes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.883%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_clf = SGDClassifier(max_iter=10, tol=None)\n",
    "svm_clf.fit(X_train_tfidf, target_train)\n",
    "\n",
    "score = round(svm_clf.score(x_test_tfidf, target_test) * 100, 3)\n",
    "print('Accuracy: {}%'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.72      0.71       346\n",
      "          2       0.73      0.08      0.14       143\n",
      "          4       0.62      0.37      0.47       578\n",
      "          5       0.72      0.92      0.80      1234\n",
      "\n",
      "avg / total       0.69      0.70      0.66      2301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = svm_clf.predict(x_test_tfidf)\n",
    "print(metrics.classification_report(target_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter tuning with GridSearch\n",
    "\n",
    "[Tuning the hyper-parameters of an estimator](http://scikit-learn.org/stable/modules/grid_search.html)\n",
    "\n",
    "Hyper-parameters are parameters that are not directly learnt within estimators.\n",
    "\n",
    "Instead of tweaking the parameters of the various components of the chain, it is possible to run an exhaustive search of the best parameters on a grid of possible values. We try out all classifiers on either words or bigrams, with or without idf, and with a penalty parameter of either 0.01 or 0.001 for the linear SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Owner\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Owner\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Owner\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Owner\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.78221997, 2.3468008 , 0.47002689, 2.75962027, 0.4628009 ,\n",
       "        1.90420341, 0.4488674 , 1.79633792]),\n",
       " 'std_fit_time': array([0.07671648, 0.27333641, 0.02483424, 1.00170188, 0.01945677,\n",
       "        0.09616504, 0.01368241, 0.04716935]),\n",
       " 'mean_score_time': array([0.3160123 , 0.52236334, 0.21867911, 0.62154984, 0.19240022,\n",
       "        0.43680072, 0.17160026, 0.43260074]),\n",
       " 'std_score_time': array([0.07041602, 0.05170299, 0.04818533, 0.15638328, 0.00735395,\n",
       "        0.01273751, 0.01273742, 0.03238825]),\n",
       " 'param_clf__alpha': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__use_idf': masked_array(data=[True, True, False, False, True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 1), (1, 2), (1, 1), (1, 2), (1, 1),\n",
       "                    (1, 2)],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__alpha': 0.01,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
       "  {'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}],\n",
       " 'split0_test_score': array([0.59666203, 0.63282337, 0.53963839, 0.57579972, 0.64951321,\n",
       "        0.67315716, 0.60083449, 0.62726008]),\n",
       " 'split1_test_score': array([0.58716876, 0.60390516, 0.56485356, 0.55509066, 0.66527197,\n",
       "        0.67364017, 0.60948396, 0.64853556]),\n",
       " 'split2_test_score': array([0.54125874, 0.60559441, 0.53426573, 0.50909091, 0.65174825,\n",
       "        0.66853147, 0.5986014 , 0.62377622]),\n",
       " 'mean_test_score': array([0.57508136, 0.61413296, 0.54625755, 0.54672245, 0.65550907,\n",
       "        0.67178057, 0.60297536, 0.63319386]),\n",
       " 'std_test_score': array([0.02417925, 0.01326169, 0.01333104, 0.02786907, 0.00696345,\n",
       "        0.00230113, 0.0046917 , 0.01094106]),\n",
       " 'rank_test_score': array([6, 4, 8, 7, 2, 1, 5, 3]),\n",
       " 'split0_train_score': array([0.70391061, 0.86452514, 0.61312849, 0.67108939, 0.90712291,\n",
       "        0.99441341, 0.7674581 , 0.87360335]),\n",
       " 'split1_train_score': array([0.69386332, 0.80474198, 0.60251046, 0.61924686, 0.91143654,\n",
       "        0.986053  , 0.72105997, 0.85146444]),\n",
       " 'split2_train_score': array([0.67688022, 0.85167131, 0.62047354, 0.60376045, 0.91016713,\n",
       "        0.9867688 , 0.75417827, 0.8718663 ]),\n",
       " 'mean_train_score': array([0.69155139, 0.84031281, 0.6120375 , 0.63136556, 0.90957553,\n",
       "        0.9890784 , 0.74756545, 0.86564469]),\n",
       " 'std_train_score': array([0.01115555, 0.02569394, 0.00737386, 0.02879171, 0.00181004,\n",
       "        0.00378372, 0.01951057, 0.010052  ])}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf     = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf     = gs_clf.fit(review_train, target_train)\n",
    "\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gs_clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
